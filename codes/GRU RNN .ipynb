{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af746a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model, ensemble, tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV,cross_validate\n",
    "from sklearn.metrics import confusion_matrix, auc,roc_auc_score,roc_curve,recall_score,classification_report\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 100, 'display.max_columns', 400)\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, auc,roc_auc_score,roc_curve,recall_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import theano\n",
    "import theano.tensor as Tensor\n",
    "import random\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import utils\n",
    "import visualize\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, BatchNormalization, Bidirectional, LayerNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import regularizers\n",
    "import re\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Activation, Dense, Flatten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf155e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = pd.read_csv('data4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2835548",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data4.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0418c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = data4.drop(['Result'], axis = 1)\n",
    "target  = data4['Result'].values\n",
    "\n",
    "train,test= train_test_split(data4, test_size=0.3,random_state=123, stratify=data4.Result)# stratify the outcome\n",
    "X_train =train.drop(['Result'], axis = 1)\n",
    "X_test = test.drop(['Result'], axis = 1)\n",
    "Y_train = train['Result'].values\n",
    "Y_test = test['Result'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a26c878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/Keras: 2.9.0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow / Keras\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Bidirectional, GRU, RepeatVector, Dense, TimeDistributed # for creating layers inside the Neural Network\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9766194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Step 1 - Specify parameters\n",
    "timestep=18\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f6fc32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler(feature_range=(-1, 1))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler(feature_range=(-1, 1))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler(feature_range=(-1, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use fit to train the scaler on the training data only, actual scaling will be done inside reshaping function\n",
    "scaler.fit(data4.to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7f5fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = data4.drop(['Result'], axis = 1)\n",
    "target  = data4['Result'].values\n",
    "\n",
    "train,test= train_test_split(data4, test_size=0.3,random_state=123, stratify=data4.Result)# stratify the outcome\n",
    "X_train =train.drop(['Result'], axis = 1)\n",
    "X_test = test.drop(['Result'], axis = 1)\n",
    "Y_train = train['Result'].values\n",
    "Y_test = test['Result'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c1dd3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "864b84b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395863, 63, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbd7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bf17639",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b91789bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(923679, 63, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e6268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e824d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dc8152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 63, 128)           50304     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 63, 128)           0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 63, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 63, 128)           99072     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 63, 128)           0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 63, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 128)               99072     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 254,178\n",
      "Trainable params: 253,410\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# GRU LAYER IS ADDED TO MODEL WITH 128 CELLS IN IT\n",
    "model.add(GRU(128, input_shape=(X_train.shape[1],X_train.shape[2]), activation='tanh', return_sequences=True))\n",
    "model.add(Dropout(0.2))  # 20% DROPOUT ADDED FOR REGULARIZATION\n",
    "model.add(BatchNormalization())\n",
    "model.add(GRU(128, input_shape=(X_train.shape[1],X_train.shape[2]), activation='tanh', return_sequences=True))   # ADD ANOTHER LAYER\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GRU(128, input_shape=(X_train.shape[1],X_train.shape[2]), activation='tanh', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation='relu'))  # ADD A DENSE LAYER\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))  # FINAL CLASSIFICATION LAYER WITH 2 CLASSES AND SOFTMAX\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# OPTIMIZER SETTINGS\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "# MODEL COMPILE\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d013f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14433/14433 [==============================] - 1699s 117ms/step - loss: 0.4168 - accuracy: 0.8195 - val_loss: 0.2919 - val_accuracy: 0.8756\n",
      "Epoch 2/10\n",
      "14433/14433 [==============================] - 2038s 141ms/step - loss: 0.2367 - accuracy: 0.8996 - val_loss: 0.1860 - val_accuracy: 0.9224\n",
      "Epoch 3/10\n",
      "14433/14433 [==============================] - 1696s 118ms/step - loss: 0.2015 - accuracy: 0.9139 - val_loss: 0.1380 - val_accuracy: 0.9375\n",
      "Epoch 4/10\n",
      " 1502/14433 [==>...........................] - ETA: 30:23 - loss: 0.1598 - accuracy: 0.9294"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    X_train, Y_train, validation_data=(X_test, Y_test), batch_size=64, epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69140fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664abd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e75ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6a73377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 64)                12864     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,770\n",
      "Trainable params: 13,642\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.GRU(64, input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(10))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cf3e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "182ff605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14433/14433 [==============================] - 395s 27ms/step - loss: 0.5064 - accuracy: 0.7921 - val_loss: 0.5104 - val_accuracy: 0.8046\n",
      "Epoch 2/10\n",
      "14433/14433 [==============================] - 383s 27ms/step - loss: 0.4675 - accuracy: 0.8041 - val_loss: 0.8586 - val_accuracy: 0.3574\n",
      "Epoch 3/10\n",
      "14433/14433 [==============================] - 387s 27ms/step - loss: 0.4600 - accuracy: 0.8047 - val_loss: 0.8323 - val_accuracy: 0.3724\n",
      "Epoch 4/10\n",
      "14433/14433 [==============================] - 384s 27ms/step - loss: 0.4569 - accuracy: 0.8056 - val_loss: 0.4568 - val_accuracy: 0.8070\n",
      "Epoch 5/10\n",
      "14433/14433 [==============================] - 386s 27ms/step - loss: 0.4558 - accuracy: 0.8058 - val_loss: 0.5643 - val_accuracy: 0.7222\n",
      "Epoch 6/10\n",
      "14433/14433 [==============================] - 378s 26ms/step - loss: 0.4551 - accuracy: 0.8059 - val_loss: 0.5029 - val_accuracy: 0.8042\n",
      "Epoch 7/10\n",
      "14433/14433 [==============================] - 388s 27ms/step - loss: 0.4538 - accuracy: 0.8061 - val_loss: 0.6653 - val_accuracy: 0.8037\n",
      "Epoch 8/10\n",
      "14433/14433 [==============================] - 389s 27ms/step - loss: 0.4530 - accuracy: 0.8063 - val_loss: 0.5490 - val_accuracy: 0.7229\n",
      "Epoch 9/10\n",
      "14433/14433 [==============================] - 388s 27ms/step - loss: 0.4522 - accuracy: 0.8067 - val_loss: 0.8060 - val_accuracy: 0.4421\n",
      "Epoch 10/10\n",
      "14433/14433 [==============================] - 379s 26ms/step - loss: 0.4520 - accuracy: 0.8069 - val_loss: 0.7034 - val_accuracy: 0.5391\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    X_train, Y_train, validation_data=(X_test, Y_test), batch_size=64, epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f016d003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afaff94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b63fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91734828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaa1af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Step 3 - Specify the structure of a Neural Network\n",
    "model = Sequential(name=\"GRU-Model\") # Model\n",
    "model.add(Input(shape=(X_train.shape[1],X_train.shape[2]), name='Input-Layer')) # Input Layer - need to speicfy the shape of inputs\n",
    "model.add(Bidirectional(GRU(units=32, activation='tanh', recurrent_activation='sigmoid', stateful=False), name='Hidden-GRU-Encoder-Layer')) # Encoder Layer\n",
    "model.add(RepeatVector(X_train.shap e[2], name='Repeat-Vector-Layer')) # Repeat Vector\n",
    "model.add(Bidirectional(GRU(units=32, activation='tanh', recurrent_activation='sigmoid', stateful=False, return_sequences=True), name='Hidden-GRU-Decoder-Layer')) # Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8539b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GRU-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden-GRU-Encoder-Layer (B  (None, 64)               6720      \n",
      " idirectional)                                                   \n",
      "                                                                 \n",
      " Repeat-Vector-Layer (Repeat  (None, 1, 64)            0         \n",
      " Vector)                                                         \n",
      "                                                                 \n",
      " Hidden-GRU-Decoder-Layer (B  (None, 1, 64)            18816     \n",
      " idirectional)                                                   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,536\n",
      "Trainable params: 25,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b09af38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "869c740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', # default='rmsprop', an algorithm to be used in backpropagation\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'],\n",
    "              #loss='mean_squared_error', # Loss function to be optimized. A string (name of loss function), or a tf.keras.losses.Loss instance.\n",
    "              #metrics=['MeanSquaredError', 'MeanAbsoluteError'], # List of metrics to be evaluated by the model during training and testing. Each of this can be a string (name of a built-in function), function or a tf.keras.metrics.Metric instance. \n",
    "              loss_weights=None, # default=None, Optional list or dictionary specifying scalar coefficients (Python floats) to weight the loss contributions of different model outputs.\n",
    "              weighted_metrics=None, # default=None, List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing.\n",
    "              run_eagerly=None, # Defaults to False. If True, this Model's logic will not be wrapped in a tf.function. Recommended to leave this as None unless your Model cannot be run inside a tf.function.\n",
    "              steps_per_execution=None # Defaults to 1. The number of batches to run during each tf.function call. Running multiple batches inside a single tf.function call can greatly improve performance on TPUs or small models with a large Python overhead.\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b8225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b475ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2449d2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6383e05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269148/923679 [=======>......................] - ETA: 2:39:47 - loss: 4.0534 - accuracy: 0.0366"
     ]
    }
   ],
   "source": [
    "#### Step 5 - Fit the model on the dataset\n",
    "history = model.fit(X_train, # input data\n",
    "                    Y_train, # target data\n",
    "                    batch_size=1, # Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "                    epochs=1, # default=1, Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided\n",
    "                    verbose=1, # default='auto', ('auto', 0, 1, or 2). Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 'auto' defaults to 1 for most cases, but 2 when used with ParameterServerStrategy.\n",
    "                    callbacks=None, # default=None, list of callbacks to apply during training. See tf.keras.callbacks\n",
    "                    validation_split=0.3, # default=0.0, Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. \n",
    "                    validation_data=(X_test, Y_test), # default=None, Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "                    shuffle=True, # default=True, Boolean (whether to shuffle the training data before each epoch) or str (for 'batch').\n",
    "                    class_weight=None, # default=None, Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "                    sample_weight=None, # default=None, Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only).\n",
    "                    initial_epoch=0, # Integer, default=0, Epoch at which to start training (useful for resuming a previous training run).\n",
    "                    steps_per_epoch=None, # Integer or None, default=None, Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. \n",
    "                    validation_steps=None, # Only relevant if validation_data is provided and is a tf.data dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch.\n",
    "                    validation_batch_size=None, # Integer or None, default=None, Number of samples per validation batch. If unspecified, will default to batch_size.\n",
    "                    validation_freq=10, # default=1, Only relevant if validation data is provided. If an integer, specifies how many training epochs to run before a new validation run is performed, e.g. validation_freq=2 runs validation every 2 epochs.\n",
    "                    max_queue_size=10, # default=10, Used for generator or keras.utils.Sequence input only. Maximum size for the generator queue. If unspecified, max_queue_size will default to 10.\n",
    "                    workers=1, # default=1, Used for generator or keras.utils.Sequence input only. Maximum number of processes to spin up when using process-based threading. If unspecified, workers will default to 1.\n",
    "                    use_multiprocessing=True, # default=False, Used for generator or keras.utils.Sequence input only. If True, use process-based threading. If unspecified, use_multiprocessing will default to False. \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c0863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b49752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4f192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
