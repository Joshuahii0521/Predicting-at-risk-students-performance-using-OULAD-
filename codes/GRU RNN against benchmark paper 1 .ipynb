{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3c1c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model, ensemble, tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV,cross_validate\n",
    "from sklearn.metrics import confusion_matrix, auc,roc_auc_score,roc_curve,recall_score,classification_report\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 100, 'display.max_columns', 400)\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, auc,roc_auc_score,roc_curve,recall_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import theano\n",
    "import theano.tensor as Tensor\n",
    "import random\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import utils\n",
    "import visualize\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, BatchNormalization, Bidirectional, LayerNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import regularizers\n",
    "import re\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Activation, Dense, Flatten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a97e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = pd.read_csv('data4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21fc7f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data4.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c60535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test= train_test_split(data4, test_size=0.3,random_state=123, stratify=data4.Result)# stratify the outcome\n",
    "X_train =train.drop(['Result'], axis = 1)\n",
    "X_test = test.drop(['Result'], axis = 1)\n",
    "Y_train = train['Result'].values\n",
    "Y_test = test['Result'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3102b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/Keras: 2.9.0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow / Keras\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Bidirectional, GRU, RepeatVector, Dense, TimeDistributed # for creating layers inside the Neural Network\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc445b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac1571b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395863, 63, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b037dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "584de8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(923679, 63, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f69ef708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 63, 50)            7950      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 63, 50)            0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 63, 50)           200       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 63, 30)            7380      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 63, 30)            0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 63, 30)           120       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 15)                2115      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 15)                0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 15)               60        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,841\n",
      "Trainable params: 17,651\n",
      "Non-trainable params: 190\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# GRU LAYER IS ADDED TO MODEL WITH 128 CELLS IN IT\n",
    "model.add(GRU(50, input_shape=(X_train.shape[1],X_train.shape[2]), activation='tanh', return_sequences=True))\n",
    "model.add(Dropout(0.2))  # 20% DROPOUT ADDED FOR REGULARIZATION\n",
    "model.add(BatchNormalization())\n",
    "model.add(GRU(30, input_shape=(X_train.shape[1],X_train.shape[2]), activation='tanh', return_sequences=True))   # ADD ANOTHER LAYER\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GRU(15, input_shape=(X_train.shape[1],X_train.shape[2]), activation='tanh', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))  # FINAL CLASSIFICATION LAYER WITH 2 CLASSES AND SOFTMAX\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# OPTIMIZER SETTINGS\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "# MODEL COMPILE\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy','Recall','Precision'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "094a3d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14433/14433 [==============================] - 1261s 87ms/step - loss: 0.4534 - accuracy: 0.8037 - recall: 0.1799 - precision: 0.7024 - val_loss: 0.4312 - val_accuracy: 0.8138 - val_recall: 0.1913 - val_precision: 0.8214\n",
      "Epoch 2/10\n",
      "14433/14433 [==============================] - 1246s 86ms/step - loss: 0.3988 - accuracy: 0.8273 - recall: 0.3232 - precision: 0.7434 - val_loss: 0.3494 - val_accuracy: 0.8516 - val_recall: 0.4460 - val_precision: 0.7834\n",
      "Epoch 3/10\n",
      "14433/14433 [==============================] - 1945s 135ms/step - loss: 0.3358 - accuracy: 0.8589 - recall: 0.4928 - precision: 0.7826 - val_loss: 0.2725 - val_accuracy: 0.8854 - val_recall: 0.6003 - val_precision: 0.8292\n",
      "Epoch 4/10\n",
      "14433/14433 [==============================] - 1709s 118ms/step - loss: 0.2881 - accuracy: 0.8815 - recall: 0.6014 - precision: 0.8088 - val_loss: 0.2322 - val_accuracy: 0.9064 - val_recall: 0.6802 - val_precision: 0.8633\n",
      "Epoch 5/10\n",
      "14433/14433 [==============================] - 1950s 135ms/step - loss: 0.2547 - accuracy: 0.8972 - recall: 0.6671 - precision: 0.8301 - val_loss: 0.2009 - val_accuracy: 0.9191 - val_recall: 0.7034 - val_precision: 0.9061\n",
      "Epoch 6/10\n",
      "14433/14433 [==============================] - 1848s 128ms/step - loss: 0.2321 - accuracy: 0.9069 - recall: 0.7052 - precision: 0.8440 - val_loss: 0.1847 - val_accuracy: 0.9254 - val_recall: 0.7402 - val_precision: 0.9018\n",
      "Epoch 7/10\n",
      "14433/14433 [==============================] - 1477s 102ms/step - loss: 0.2160 - accuracy: 0.9135 - recall: 0.7312 - precision: 0.8530 - val_loss: 0.1710 - val_accuracy: 0.9307 - val_recall: 0.7846 - val_precision: 0.8858\n",
      "Epoch 8/10\n",
      "14433/14433 [==============================] - 1401s 97ms/step - loss: 0.2038 - accuracy: 0.9182 - recall: 0.7503 - precision: 0.8585 - val_loss: 0.1563 - val_accuracy: 0.9363 - val_recall: 0.8203 - val_precision: 0.8807\n",
      "Epoch 9/10\n",
      "14433/14433 [==============================] - 1300s 90ms/step - loss: 0.1943 - accuracy: 0.9222 - recall: 0.7659 - precision: 0.8635 - val_loss: 0.1545 - val_accuracy: 0.9359 - val_recall: 0.8119 - val_precision: 0.8861\n",
      "Epoch 10/10\n",
      "14433/14433 [==============================] - 1344s 93ms/step - loss: 0.1869 - accuracy: 0.9250 - recall: 0.7757 - precision: 0.8678 - val_loss: 0.1627 - val_accuracy: 0.9338 - val_recall: 0.7990 - val_precision: 0.8873\n"
     ]
    }
   ],
   "source": [
    "# RUN THE MODEL\n",
    "history = model.fit(X_train, Y_train, epochs=10, batch_size=64, verbose=1,\n",
    "                    validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311be6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273c66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334195f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
